{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "> Define the data classes using Pydantic, making it possible to configure the chat application and do input validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List, Tuple, Literal, Any\n",
    "import os\n",
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The theme of the Gradio Chat App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AppTheme data class makes it possible to configure the _colors_ and optionally a _logo_.\n",
    "\n",
    "The logo's should be stored within the data folder of the project for easy acces. In future iterations the logo's can be retrieved from:\n",
    "- the web\n",
    "- a database\n",
    "- a datafolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The configuration for the workings of the LLM chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the configuration for the LLM model to use in the `ModelConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ModelConfig(BaseModel):\n",
    "    \"\"\"Configuration for the LLM model\"\"\"\n",
    "    model_name: str = Field(..., description=\"Name or path of the model to use\")\n",
    "    provider: str = Field(default=\"huggingface\", description=\"Model provider (huggingface, openai, etc)\")\n",
    "    api_key_env_var: Optional[str] = Field(default=None, description=\"Environment variable name for API key\")\n",
    "    api_base_url: Optional[str] = Field(default=None, description=\"Base URL for API reqeuest\")\n",
    "    max_tokens: int = Field(default=1024, description=\"Maximum tokens to generate\")\n",
    "    temperature: float = Field(default=0.7, description=\"Temperature for generation\")\n",
    "    stop_sequences: Optional[List[str]] = Field(default=[\"\\nUser:\", \"<|endoftext|>\"], description=\"Sequences to stop generation\")\n",
    "    \n",
    "    @property\n",
    "    def api_key(self) -> Optional[str]:\n",
    "        \"\"\"Get the API key from environment variables if specified\"\"\"\n",
    "        if self.api_key_env_var:\n",
    "            if os.environ.get(self.api_key_env_var):\n",
    "                return os.environ.get(self.api_key_env_var)\n",
    "            raise ValueError(f\"The environment variable {self.api_key_env_var} is not found in the .env file.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the configuration of the Message system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Message(BaseModel):\n",
    "    \"\"\"A message in a conversation\"\"\"\n",
    "    role: Literal[\"system\", \"user\", \"assistant\"] = Field(..., description=\"Role of the message sender\")\n",
    "    content: str = Field(..., description=\"Content of the message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the configuration for the chat implementation. Making sure the application can handle:\n",
    "- system prompt\n",
    "- context if applicable\n",
    "- a start 'user' prompt if applicable\n",
    "- user input\n",
    "\n",
    "The other settings that are available in this class can easily be infered from the description in the `ChatAppConfig` class itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ChatAppConfig(BaseModel):\n",
    "    \"\"\"Main configuration for a chat application\"\"\"\n",
    "    app_name: str = Field(..., description=\"Name of the application\")\n",
    "    description: str = Field(default=\"\", description=\"Description of the application\")\n",
    "    system_prompt: str = Field(..., description=\"System prompt for the LLM\")\n",
    "    starter_prompt: Optional[str] = Field(default=None, description=\"Initial prompt to start the conversation\")\n",
    "    context_files: List[Path] = Field(default=[], description=\"List of markdown files for additional context\")\n",
    "    model: ModelConfig\n",
    "    theme: Optional[Any] = Field(default=None, description=\"Gradio theme to use\")\n",
    "    logo_path: Optional[Path] = Field(default=None, description=\"Path to logo image\")\n",
    "    show_system_prompt: bool = Field(default=True, description=\"Whether to show system prompt in UI\")\n",
    "    show_context: bool = Field(default=True, description=\"Whether to show context in UI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example configuration for a chat application could look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"app_name\": \"Test App\",\n",
      "  \"description\": \"\",\n",
      "  \"system_prompt\": \"You are a helpful assistant.\",\n",
      "  \"starter_prompt\": null,\n",
      "  \"context_files\": [],\n",
      "  \"model\": {\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"provider\": \"huggingface\",\n",
      "    \"api_key_env_var\": \"HF_API_KEY\",\n",
      "    \"api_base_url\": null,\n",
      "    \"max_tokens\": 1024,\n",
      "    \"temperature\": 0.7,\n",
      "    \"stop_sequences\": [\n",
      "      \"\\nUser:\",\n",
      "      \"<|endoftext|>\"\n",
      "    ]\n",
      "  },\n",
      "  \"theme\": null,\n",
      "  \"logo_path\": null,\n",
      "  \"show_system_prompt\": true,\n",
      "  \"show_context\": true\n",
      "}\n",
      "API Key available: Yes\n"
     ]
    }
   ],
   "source": [
    "test_config = ChatAppConfig(\n",
    "    app_name=\"Test App\",\n",
    "    system_prompt=\"You are a helpful assistant.\",\n",
    "    model=ModelConfig(\n",
    "        model_name=\"gpt-3.5-turbo\",\n",
    "        api_key_env_var=\"HF_API_KEY\",\n",
    "    )\n",
    ")\n",
    "\n",
    "print(test_config.model_dump_json(indent=2))\n",
    "\n",
    "print(f\"API Key available: {'Yes' if test_config.model.api_key else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
